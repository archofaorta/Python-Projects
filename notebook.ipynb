{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1><font color=\"teal\">Sample Data Analysis - Automation Code (Genesis WS1)</font></h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import date\n",
    "print('Run date:')\n",
    "print(str(date.today())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"purple\">Import libraries and set working directory</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir('C:\\\\Users\\\\kv23857\\\\Documents\\\\DAT\\\\ALL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.getcwd()\n",
    "print(filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"blue\">Enter Product Name (pos, tp, lns, cad, dep, dev)</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodname = 'dep'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"purple\">Function to set TRL filename, sheetnames, and sample dataset names based on given product name</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if prodname=='dep':\n",
    "    trl_filename = 'Deposit_TRL_V15.xlsx'\n",
    "    trl_data = ['Indicative Data - Deposits', 'Indicative-Extension', 'Deposit Collateral','Arrng Involved Party','Common Balance']\n",
    "    sample_data = ['id', 'ide', 'col', 'ip', 'cb']\n",
    "elif prodname == 'lns':\n",
    "    trl_filename = 'Corporate_Loans_TRL_V16.xlsx'\n",
    "    trl_data = ['Indicative Record','Arrangement Involved Parties','Arrangement Associations','Arrangement Rates','Installments','Arrng Loss Mitigation','Common Balance']\n",
    "    sample_data = ['id','ip','arar','ar','ins','alm','cb']\n",
    "elif prodname == 'pos':\n",
    "    trl_filename = 'Security_Positions_Target_Layout_V15.xlsx'\n",
    "    trl_data = ['Financial Market Position','Account Reference','Common Balance','Hedge']\n",
    "    sample_data = ['id','ar','cb','hdge']\n",
    "elif prodname == 'tp':\n",
    "    trl_filename = 'Trade_Products_TRL_V15.xlsx'\n",
    "    trl_data = ['Indicative','Arrangement Associations','Arrangement Involved Parties','Arrangement Rates','Arrangement Participation','Arrangement Alt Id','Arrng Modification','Common Balance']\n",
    "    sample_data = ['id','aa','ip','ar','ap','alt','am','cb']\n",
    "elif prodname == 'dev':\n",
    "    trl_filename = 'OTC_Derivative_TRL_V15.xlsx'\n",
    "    trl_data = ['Core OTC Deriv Arr','OTC Deriv Leg','Account Reference Data','Arr Assoc','Common Balance','Incr OTC Deriv Arr','Incr OTC Payment Schd','Incr OTC Option Exercise Schd']\n",
    "    sample_data = ['ocda','odl','ar','oaa','ocb','oida','ps','oioe']\n",
    "else:\n",
    "    print(\"Error - incorrect product name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trl = pd.ExcelFile(trl_filename)\n",
    "trl.sheet_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"purple\">Create list of all sample data filenames within folder in given path</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dat = os.listdir(filepath)\n",
    "list_dat = [x for x in list_dat if '.dat' in x]\n",
    "print(len(list_dat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"purple\">Function to convert all input data cols to string/object type while importing to python</font></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts all columns to a string or object datatype while importing .dat file to Python\n",
    "class StringConverter(dict):\n",
    "    def __contains__(self, item):\n",
    "        return True\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return str\n",
    "\n",
    "    def get(self, default=None):\n",
    "        return str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"purple\">Loop through sample data files for given product and concatenate data into one master dataframe</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create empty dataframe\n",
    "df_master = pd.DataFrame()\n",
    "# loop through each dat files \n",
    "for each_dat in list_dat:\n",
    "    if each_dat.split('_')[2] == prodname:\n",
    "        temp_path_dat = os.path.join(filepath, each_dat)\n",
    "        # temporary dataframe\n",
    "        col_names = list(range(0,500)) \n",
    "        df_temp = pd.read_csv(temp_path_dat,sep=\"|\",header=None,converters=StringConverter(),names=col_names,encoding='unicode_escape')\n",
    "\n",
    "        # add a column with the datetime from filename\n",
    "        df_temp['Filename'] = each_dat\n",
    "        df_temp['CSI ID'] = each_dat.split('_')[1]\n",
    "        df_temp['Product'] = each_dat.split('_')[2]\n",
    "        df_temp['Dataset'] = each_dat.split('_')[3]\n",
    "        df_temp['Country'] = each_dat.split('_')[5]\n",
    "        dat = each_dat.split('_')[-1]\n",
    "        df_temp['Date/Timestamp'] = dat.split('.')[0]\n",
    "        # concatenate dataframes\n",
    "        df_master = pd.concat([df_master, df_temp])\n",
    "\n",
    "    # reset the dataframe index\n",
    "    df_master = df_master.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"purple\">Create dictionary of dataframes for each unique sample dataset</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dataset = df_master.Dataset.unique()\n",
    "df_dict = {name: df_master.loc[df_master['Dataset'] == name] for name in unique_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Display all dataset names\n",
    "print(len(df_dict))\n",
    "df_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"purple\">Parse the TRL file for given sheetnames</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet_name in trl.sheet_names:\n",
    "    trl_dict = trl.parse(trl_data,dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trl_dict))\n",
    "trl_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trl_dict['Common Balance'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=\"purple\">Loop through TRL sheets to check for 'Business Attribute Name' and send to concatenated list.</font></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in trl_dict.items():\n",
    "    attr_cols = [col for col in y.columns if 'Business Attribute Name' in col]\n",
    "    print(x,attr_cols)\n",
    "    y = y[~y['Business Attribute Name'].isnull()]\n",
    "    trl_dict[x]= y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_series = []\n",
    "for k, v in trl_dict.items():\n",
    "    temp = v['Business Attribute Name'].tolist()\n",
    "    attr_series.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(sample_data):\n",
    "    attr_series[i].append(sample_data[i])\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemDict = {attr[-1]: attr for attr in attr_series}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"purple\">Assign TRL business attribute names as column headers for each sample dataset.</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_dict = df_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in new_df_dict.items():\n",
    "    new_df_dict[key] = new_df_dict[key].reset_index(drop=True)  \n",
    "    newcols = ['0']\n",
    "    newlist = itemDict[key].copy()\n",
    "    newcols.extend(newlist)\n",
    "    newcols.extend(list(range(new_df_dict[key].shape[1]-len(newcols))))\n",
    "    new_df_dict[key].columns = newcols  \n",
    "    new_df_dict[key].drop(new_df_dict[key].iloc[:,len(newlist):-6], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d,p in new_df_dict.items():\n",
    "    p.rename(columns={'0': 'H_D_T',p.columns[-6]: 'Filename', p.columns[-5]: 'CSI ID',p.columns[-4]: 'Product',p.columns[-3]: 'Dataset',p.columns[-2]: 'Country',p.columns[-1]: 'Date/Timestamp'},inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_dict['cb'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"purple\">Export sample datasets with assigned column headers and metadata details to csv files</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in new_df_dict: \n",
    "    new_df_dict[i].to_csv(prodname+'_sampledata_'+str(i)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"purple\">Function to format each product TRL and create master dataframe (analysis document)</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dep_trl_func(d):\n",
    "    for k, i in d.items():\n",
    "        global masterdf\n",
    "        i['Dataset'] = k\n",
    "        #checkcols = [check for check in i.columns if 'Remarks' in check]\n",
    "        #print(k, ' : ',checkcols)\n",
    "        matchers = ['Dataset','Physical','Business Attribute', 'Data Type & Length','Mandatory','Attribute Description','Expected','Default','CDE Name', 'Tracking','CDE', 'Remarks']\n",
    "        matching = [s for s in i.columns if any(xs in s for xs in matchers)]\n",
    "        #print(k,matching)\n",
    "        x = i.columns[i.columns.str.contains('pdate')]\n",
    "        i = i.drop(columns=x)\n",
    "        i = i.drop(columns=[col for col in i if col not in matching])\n",
    "        #print(k,\" - \", len(i.columns))\n",
    "        #print(i.columns)\n",
    "        i.columns = ['Element Name','Description','Data Type & Length', 'MCO','Remarks', 'Expected Domain Values', 'Default Values','CDE Tracking ID', 'CDE Name', 'Drop','Drop','Drop','Drop','CDE','Physical Name','Dataset']\n",
    "        i = i.drop(columns = 'Drop')\n",
    "        d[k]= i\n",
    "        masterdf = pd.concat(d, axis=0,sort=False).reset_index()\n",
    "    return masterdf                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prodname == 'lns':\n",
    "    print(\"Executing TRL cleanup function for Loans sample data...\")\n",
    "    lns_trl_func(trl_dict)\n",
    "elif prodname == 'pos':\n",
    "    print(\"Executing TRL cleanup function for Security Positions sample data...\")\n",
    "    pos_trl_func(trl_dict)\n",
    "elif prodname == 'tp':\n",
    "    print(\"Executing TRL cleanup function for Traded Products sample data ...\")\n",
    "    tp_trl_func(trl_dict)\n",
    "elif prodname == 'dep':\n",
    "    print(\"Executing TRL cleanup function for Deposits sample data...\")\n",
    "    dep_trl_func(trl_dict)\n",
    "    unique_dataset = masterdf.level_0.unique()\n",
    "    masterdf.level_0 = masterdf.level_0.apply(lambda x: sample_data[0] if unique_dataset[0] in x else sample_data[1] if unique_dataset[1] in x else sample_data[2] if unique_dataset[2] in x else sample_data[3] if unique_dataset[3] in x else sample_data[4] if unique_dataset[4] in x else x)    \n",
    "    print(masterdf.keys())\n",
    "elif prodname == 'dev':\n",
    "    print(\"Executing TRL cleanup function for OTC sample data...\")\n",
    "    otc_trl_func(trl_dict)\n",
    "    unique_dataset = masterdf.level_0.unique()\n",
    "    masterdf.level_0 = masterdf.level_0.apply(lambda x: sample_data[0] if unique_dataset[0] in x else sample_data[1] if unique_dataset[1] in x else sample_data[2] if unique_dataset[2] in x else sample_data[3] if unique_dataset[3] in x else sample_data[4] if unique_dataset[4] in x else sample_data[5] if unique_dataset[5] in x else sample_data[6] if unique_dataset[6] in x else sample_data[7] if unique_dataset[7] in x else sample_data[8] if unique_dataset[8] in x else x)   \n",
    "    print(masterdf.keys())\n",
    "else:\n",
    "    print(\"Error - incorrect product name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf.drop(columns = 'level_1',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"purple\">Add sample data analysis columns to the master dataframe</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf2 = masterdf[~masterdf['Element Name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf2 = masterdf2.reindex(columns=[*masterdf2.columns.tolist(), 'Null/Not Null/Zero', 'Number of Records Analyzed', 'Sample Data File Date', 'Sample Data Source', 'Representative Sample Values','Sample Data Analyzed for Country','Filename', 'Potential Gap','Observations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf2.columns[masterdf2.isna().all()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"purple\">Send sample data to 'Representative Sample Values' column</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = []\n",
    "for j,k in new_df_dict.items():\n",
    "    data = k.iloc[1].tolist()\n",
    "    data1.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_list = sorted(data1, key=lambda x:sample_data.index(x[-3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for qwe in new_list:\n",
    "    if qwe[0] == 'T':\n",
    "        qwe[1]= 'No Data Available'\n",
    "        qwe[2]= ''\n",
    "        qwe[3]= ''\n",
    "        qwe[4]= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_list = [i[1:-6] for i in new_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "append_list = [item for sublist in result_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "masterdf2['Representative Sample Values'] = append_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"purple\">Assign values to 'Null/Not Null/Zero' column based on sample values</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "masterdf2['Representative Sample Values']=masterdf2['Representative Sample Values'].replace(r'^\\s*$', np.nan, regex=True).fillna('--')\n",
    "masterdf2['Null/Not Null/Zero'] = pd.np.where(masterdf2['Representative Sample Values'].str.contains(\"--\"),\"Null\", pd.np.where(masterdf2['Representative Sample Values'].str.strip()==(\"0\"),\"Zero\",\"Not Null\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "masterdf2[['Null/Not Null/Zero','Representative Sample Values']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"darkblue\">Assign values to 'Sample Data File Date' column based on sample values</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "check_list = [len(i) for i in result_list]\n",
    "print(check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sum(check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datelist11=[]\n",
    "for j,k in new_df_dict.items():\n",
    "    datelist = k['Date/Timestamp'].unique().tolist()\n",
    "    datasetlist = k.Dataset.unique().tolist()\n",
    "    datelist1 = datelist + datasetlist\n",
    "    datelist11.append(datelist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove empty strings from nested list\n",
    "# b = [[i for i in item if i != ''] for item in datelist11]\n",
    "# c = [item for item in b if item != []]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(datelist11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datelist2 = sorted(datelist11, key=lambda w:sample_data.index(w[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(datelist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finaldd=[]\n",
    "for i in range(len(check_list)):\n",
    "    date=[el[0] for el in datelist2][i]\n",
    "    dd= (np.repeat(date,check_list[i])).tolist()\n",
    "    i +=1\n",
    "    lyst = [x for x in dd]\n",
    "    finaldd.append(lyst)\n",
    "    finaldd2 = [item for sublist in finaldd for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(finaldd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "masterdf2['Sample Data File Date'] = finaldd2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"darkblue\">Assign values to 'Filename', 'Sample Data Analyzed for Country', 'Number of Records Analyzed', 'Sample Data File Date', and 'Sample Data Source' columns</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filelist1=[]\n",
    "for j,k in new_df_dict.items():\n",
    "    filelist = k.Filename.unique().tolist()\n",
    "    countrylist = k.Country.unique().tolist()\n",
    "    datasetlist = k.Dataset.unique().tolist()\n",
    "    newlist = filelist + countrylist + datasetlist\n",
    "    filelist1.append(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filelist2 = sorted(filelist1, key=lambda w:sample_data.index(w[-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filelist2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finalff=[]\n",
    "for i in range(len(check_list)):\n",
    "    file=[el[0] for el in filelist2][i]\n",
    "    ff= (np.repeat(file,check_list[i])).tolist()\n",
    "    i +=1\n",
    "    lyst = [x for x in ff]\n",
    "    finalff.append(lyst)\n",
    "    finalff2 = [item for sublist in finalff for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(finalff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "masterdf2['Filename'] = finalff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalcc=[]\n",
    "for i in range(len(check_list)):\n",
    "    country=[el[1] for el in filelist2][i]\n",
    "    cc= (np.repeat(country,check_list[i])).tolist()\n",
    "    i +=1\n",
    "    lyst = [x for x in cc]\n",
    "    finalcc.append(lyst)\n",
    "    finalcc2 = [item for sublist in finalcc for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(finalcc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf2['Sample Data Analyzed for Country'] = finalcc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthlist =[]\n",
    "for j,k in new_df_dict.items():\n",
    "    chk = len(k['H_D_T'])\n",
    "    chk = [chk-2]\n",
    "    datasetlist = k.Dataset.unique().tolist()\n",
    "    lenlist = chk+datasetlist\n",
    "    lengthlist.append(lenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lengthlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthlist2 = sorted(lengthlist, key=lambda w:sample_data.index(w[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lengthlist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalz=[]\n",
    "for i in range(len(check_list)):\n",
    "    global lyst\n",
    "    length = [el[0] for el in lengthlist2][i]\n",
    "    ll= (np.repeat(length,check_list[i])).tolist()\n",
    "    i +=1\n",
    "    lyst = [x for x in ll]\n",
    "    finalz.extend(lyst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf2['Number of Records Analyzed'] =finalz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf2['Sample Data Source']='Production' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf2.to_csv(prodname + '_TRL_Analysis' +'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3><font color=\"darkblue\">WIP - Potential Gaps and Observations</font></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf3 = masterdf2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf3['MCO']=masterdf3['MCO'].fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf3['Potential Gap'] = np.where(masterdf3['MCO'].str.contains('M') & masterdf3['Null/Not Null/Zero']==\"Null\", 'Y', 'N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf3[['Null/Not Null/Zero','MCO','Potential Gap']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf3.to_csv(prodname + '_TRL_Analysis_updates' +'.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
